{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQK7KlhRBfnf",
    "pycharm": {}
   },
   "source": [
    "# Step 1 : Convert Keras model into TensorRT model\n",
    "**adatped from [How to run Keras model on Jetson Nano](https://www.dlology.com/blog/how-to-run-keras-model-on-jetson-nano/) | DLology Blog**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITUc4J7etACS",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VsZgX4XeuNkt",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Download an image for prediction.\n",
    "\n",
    "!wget --quiet https://raw.githubusercontent.com/Tony607/tf_jetson_nano/master/data/elephant.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "fWygvIyctpeI",
    "outputId": "d2dea334-f704-4658-a495-c3c9d559e472",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0717 14:10:42.030561 139633430599424 deprecation.py:506] From /home/romilly/envs/tf-benchmarks/lib/python3.5/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02504458', 'African_elephant', 0.7051347), ('n01871265', 'tusker', 0.1551431), ('n02504013', 'Indian_elephant', 0.039011452)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 as Net\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Optional image to test model prediction.\n",
    "img_path = './elephant.jpg'\n",
    "model_path = './model'\n",
    "\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "# Path to save the model h5 file.\n",
    "model_fname = os.path.join(model_path, 'model-mobV2.h5')\n",
    "\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "img_height = 224\n",
    "\n",
    "model = Net(weights='imagenet')\n",
    "\n",
    "\n",
    "# Load the image for prediction.\n",
    "img = image.load_img(img_path, target_size=(img_height, img_height))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])\n",
    "# Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]\n",
    "\n",
    "# Save the h5 file to path specified.\n",
    "model.save(model_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OY9k1o9iulZF",
    "pycharm": {}
   },
   "source": [
    "### Benchmark Keras prediction speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "kGqN3UXquW-m",
    "outputId": "450a9e18-310e-4ec7-a6ec-34f508e743c3",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average(sec):0.03811124563217163,fps:26.238974439498495\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "times = []\n",
    "for i in range(20):\n",
    "    start_time = time.time()\n",
    "    preds = model.predict(x)\n",
    "    delta = (time.time() - start_time)\n",
    "    times.append(delta)\n",
    "mean_delta = np.array(times).mean()\n",
    "fps = 1/mean_delta\n",
    "print('average(sec):{},fps:{}'.format(mean_delta,fps))\n",
    "\n",
    "# Clear any previous session.\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FBsv7z2WukCz",
    "pycharm": {}
   },
   "source": [
    "## Freeze graph, generate `.pb` file.\n",
    "Take a notes of the input and output nodes names printed in the output, we will need them when converting `TensorRT` graph and prediction.\n",
    "\n",
    "For Keras MobileNetV2, they are,\n",
    "```\n",
    "['input_1'] ['Logits/Softmax']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "id": "L-Jx1Yq0uejv",
    "outputId": "1f71e55c-8c33-4d66-92da-1240036c8bd8",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/romilly/envs/tf1-13/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "['input_1'] ['Logits/Softmax']\n",
      "WARNING:tensorflow:From <ipython-input-1-e04ec5e9bcc3>:16: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.remove_training_nodes\n",
      "WARNING:tensorflow:From <ipython-input-1-e04ec5e9bcc3>:17: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /home/romilly/envs/tf1-13/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 262 variables.\n",
      "INFO:tensorflow:Converted 262 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# force reset ipython namespaces\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Clear any previous session.\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "save_pb_dir = './model'\n",
    "model_fname = './model/model-mobV2.h5'\n",
    "def freeze_graph(graph, session, output, save_pb_dir='.', save_pb_name='frozen_model.pb', save_pb_as_text=False):\n",
    "    with graph.as_default():\n",
    "        graphdef_inf = tf.graph_util.remove_training_nodes(graph.as_graph_def())\n",
    "        graphdef_frozen = tf.graph_util.convert_variables_to_constants(session, graphdef_inf, output)\n",
    "        graph_io.write_graph(graphdef_frozen, save_pb_dir, save_pb_name, as_text=save_pb_as_text)\n",
    "        return graphdef_frozen\n",
    "\n",
    "# This line must be executed before loading Keras model.\n",
    "tf.keras.backend.set_learning_phase(0) \n",
    "\n",
    "model = load_model(model_fname)\n",
    "\n",
    "session = tf.keras.backend.get_session()\n",
    "\n",
    "input_names = [t.op.name for t in model.inputs]\n",
    "output_names = [t.op.name for t in model.outputs]\n",
    "\n",
    "# Prints input and output nodes names, take note of them.\n",
    "print(input_names, output_names)\n",
    "\n",
    "frozen_graph = freeze_graph(session.graph, session, [out.op.name for out in model.outputs], save_pb_dir=save_pb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38l-D915vahb",
    "pycharm": {}
   },
   "source": [
    "## Optimize with TensorRT\n",
    "Save the result as `.pb` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "g9qanB3Du2i-",
    "outputId": "57f5f966-3b13-468d-de5e-fd812710027a",
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running against TensorRT version 5.0.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.contrib.tensorrt as trt\n",
    "\n",
    "trt_graph = trt.create_inference_graph(\n",
    "    input_graph_def=frozen_graph,\n",
    "    outputs=output_names,\n",
    "    max_batch_size=1,\n",
    "    max_workspace_size_bytes=1 << 25,\n",
    "    precision_mode='FP16',\n",
    "    minimum_segment_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Azhh5OA2vI72",
    "outputId": "0aa4643a-42cc-46de-df0a-97829cd9931a",
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model/trt_graph.pb'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_io.write_graph(trt_graph, \"./model/\",\n",
    "                     \"trt_graph.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Hg6qDGIwmQn",
    "pycharm": {}
   },
   "source": [
    "**Next step**: transfer the `trt_graph.pb` to your Jetson Nano, load it up and make predictions.\n",
    "\n",
    "\n",
    "`Step2_keras-jetson-ImageNet-predict.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4b6xtTKp_ve7",
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Step1_Colab_TensorRT.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "tf1-13",
   "language": "python",
   "name": "tf1-13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}